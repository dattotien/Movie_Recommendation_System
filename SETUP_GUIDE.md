# ğŸš€ HÆ¯á»šNG DáºªN KHá»I Äá»˜NG Há»† THá»NG - MOVIE RECOMMENDATION SYSTEM

HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c Ä‘á»ƒ khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng tá»« Ä‘áº§u.

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [BÆ°á»›c 1: Khá»Ÿi Ä‘á»™ng Docker](#bÆ°á»›c-1-khá»Ÿi-Ä‘á»™ng-docker)
2. [BÆ°á»›c 2: Kiá»ƒm tra Services](#bÆ°á»›c-2-kiá»ƒm-tra-services)
3. [BÆ°á»›c 3: Setup HDFS](#bÆ°á»›c-3-setup-hdfs)
4. [BÆ°á»›c 4: Train Model (Náº¿u chÆ°a cÃ³)](#bÆ°á»›c-4-train-model-náº¿u-chÆ°a-cÃ³)
5. [BÆ°á»›c 5: Push Model lÃªn HDFS](#bÆ°á»›c-5-push-model-lÃªn-hdfs)
6. [BÆ°á»›c 6: Cháº¡y Batch Job (Write Recommendations)](#bÆ°á»›c-6-cháº¡y-batch-job-write-recommendations)
7. [BÆ°á»›c 7: Táº¡o Kafka Topic](#bÆ°á»›c-7-táº¡o-kafka-topic)
8. [BÆ°á»›c 8: Cháº¡y Stream Processing](#bÆ°á»›c-8-cháº¡y-stream-processing)
9. [BÆ°á»›c 9: Cháº¡y Web Application](#bÆ°á»›c-9-cháº¡y-web-application)
10. [BÆ°á»›c 10: Test Há»‡ Thá»‘ng](#bÆ°á»›c-10-test-há»‡-thá»‘ng)

---

## BÆ¯á»šC 1: Khá»Ÿi Ä‘á»™ng Docker

### 1.1. Má»Ÿ terminal Ubuntu vÃ  di chuyá»ƒn vÃ o thÆ° má»¥c project:

```bash
# TrÃªn Ubuntu/WSL
cd /mnt/d/Big_Data/Movie_Recommendation_System

# Hoáº·c náº¿u mount á»Ÿ vá»‹ trÃ­ khÃ¡c:
cd ~/Big_Data/Movie_Recommendation_System

# Kiá»ƒm tra Ä‘Ã£ vÃ o Ä‘Ãºng thÆ° má»¥c:
pwd
ls -la
```

### 1.2. Kiá»ƒm tra Docker Ä‘Ã£ cÃ i Ä‘áº·t:

```bash
# Kiá»ƒm tra Docker version
docker --version

# Kiá»ƒm tra Docker Compose
docker compose version

# Náº¿u chÆ°a cÃ³, cÃ i Ä‘áº·t:
# sudo apt-get update
# sudo apt-get install docker.io docker-compose
```

### 1.3. Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services:

```bash
# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ containers
docker compose up -d

# Xem logs khi khá»Ÿi Ä‘á»™ng
docker compose up -d && docker compose logs -f
```

### 1.4. Kiá»ƒm tra containers Ä‘ang cháº¡y:

```bash
# Xem táº¥t cáº£ containers
docker compose ps

# Hoáº·c dÃ¹ng lá»‡nh Docker thÃ´ng thÆ°á»ng
docker ps

# Xem chi tiáº¿t má»™t container
docker ps | grep app
```

**Káº¿t quáº£ mong Ä‘á»£i:** Táº¥t cáº£ 6 containers Ä‘á»u `Up`:
- `zookeeper`
- `kafka`
- `namenode`
- `datanode`
- `cassandra`
- `app`

### 1.5. Äá»£i services khá»Ÿi Ä‘á»™ng hoÃ n toÃ n (30-60 giÃ¢y):

```bash
# Kiá»ƒm tra logs Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng cÃ³ lá»—i
docker compose logs --tail=50

# Xem logs cá»§a tá»«ng service
docker compose logs namenode
docker compose logs datanode
docker compose logs cassandra
docker compose logs kafka

# Xem logs real-time
docker compose logs -f

# Kiá»ƒm tra health cá»§a containers
docker compose ps
# Táº¥t cáº£ pháº£i cÃ³ status "Up" vÃ  "healthy" (náº¿u cÃ³ healthcheck)
```

---

## BÆ¯á»šC 2: Kiá»ƒm tra Services

### 2.1. VÃ o container `app`:

```bash
# VÃ o container app
docker compose exec app bash

# Kiá»ƒm tra Ä‘Ã£ vÃ o container (prompt sáº½ Ä‘á»•i thÃ nh root@...)
whoami
hostname
pwd
```

### 2.2. Kiá»ƒm tra káº¿t ná»‘i cÃ¡c services:

```bash
# Kiá»ƒm tra HDFS
hdfs dfsadmin -report

# Kiá»ƒm tra HDFS cÃ³ thá»ƒ truy cáº­p
hdfs dfs -ls /

# Kiá»ƒm tra Cassandra (tá»« trong container)
python3 -c "from cassandra.cluster import Cluster; c = Cluster(['cassandra']); c.connect(); print('âœ… Cassandra OK')"

# Hoáº·c dÃ¹ng cqlsh (náº¿u cÃ³)
# cqlsh cassandra 9042

# Kiá»ƒm tra Kafka (tá»« trong container)
# (Kafka sáº½ Ä‘Æ°á»£c test á»Ÿ bÆ°á»›c 7)

# Kiá»ƒm tra Python vÃ  packages
python3 --version
pip list | grep -E "pyspark|cassandra|kafka"

# ThoÃ¡t container (khi cáº§n)
exit
```

---

## BÆ¯á»šC 3: Setup HDFS

### 3.1. VÃ o container app (náº¿u chÆ°a vÃ o):

```bash
docker compose exec app bash
```

### 3.2. Kiá»ƒm tra data cÃ³ sáºµn trong container:

```bash
# Kiá»ƒm tra data Ä‘Ã£ mount chÆ°a
ls -la /app/data/
ls -la /app/data/ml-32m/ml-32m/

# Kiá»ƒm tra file sizes
du -sh /app/data/ml-32m/ml-32m/*
```

### 3.3. Táº¡o thÆ° má»¥c trÃªn HDFS:

```bash
# Táº¡o thÆ° má»¥c trÃªn HDFS
hdfs dfs -mkdir -p /user/hadoop
hdfs dfs -mkdir -p /user/hadoop/movielens
hdfs dfs -mkdir -p /user/hadoop/movielens/32M

# Kiá»ƒm tra Ä‘Ã£ táº¡o thÃ nh cÃ´ng
hdfs dfs -ls -R /user/hadoop
```

### 3.4. Upload data lÃªn HDFS (náº¿u chÆ°a cÃ³):

```bash
# Kiá»ƒm tra xem Ä‘Ã£ cÃ³ data chÆ°a
hdfs dfs -ls /user/hadoop/movielens/32M

# Náº¿u chÆ°a cÃ³, upload tá»«ng file:
echo "Äang upload ratings.csv..."
hdfs dfs -put /app/data/ml-32m/ml-32m/ratings.csv /user/hadoop/movielens/32M/

echo "Äang upload movies.csv..."
hdfs dfs -put /app/data/ml-32m/ml-32m/movies.csv /user/hadoop/movielens/32M/

echo "Äang upload links.csv..."
hdfs dfs -put /app/data/ml-32m/ml-32m/links.csv /user/hadoop/movielens/32M/

# Kiá»ƒm tra láº¡i
hdfs dfs -ls -h /user/hadoop/movielens/32M

# Xem kÃ­ch thÆ°á»›c file trÃªn HDFS
hdfs dfs -du -h /user/hadoop/movielens/32M
```

**Hoáº·c dÃ¹ng script cÃ³ sáºµn:**

```bash
# Kiá»ƒm tra script cÃ³ quyá»n thá»±c thi
ls -la /app/scripts/load_to_hdfs.sh

# Náº¿u chÆ°a cÃ³ quyá»n, thÃªm quyá»n
chmod +x /app/scripts/load_to_hdfs.sh

# Cháº¡y script
bash /app/scripts/load_to_hdfs.sh

# Hoáº·c
/app/scripts/load_to_hdfs.sh
```

---

## BÆ¯á»šC 4: Train Model (Náº¿u chÆ°a cÃ³)

### 4.1. Kiá»ƒm tra xem Ä‘Ã£ cÃ³ model chÆ°a:

```bash
# Kiá»ƒm tra trÃªn HDFS
hdfs dfs -ls /user/hadoop/als_model

# Kiá»ƒm tra local trong container
ls -la /app/src/batch/als_model_32m

# Hoáº·c kiá»ƒm tra tá»« Ubuntu (ngoÃ i container)
ls -la /mnt/d/Big_Data/Movie_Recommendation_System/src/batch/als_model_32m
```

### 4.2. Náº¿u CHÆ¯A cÃ³ model, train model:

```bash
# Má»Ÿ Jupyter Notebook
# (Tá»« browser: http://localhost:8888)
# Hoáº·c cháº¡y trá»±c tiáº¿p tá»« notebook:
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root

# Má»Ÿ file: /app/src/batch/train_model.ipynb
# Cháº¡y cÃ¡c cells Ä‘á»ƒ train model
# LÆ°u model vÃ o: /app/src/batch/als_model_32m
```

**LÆ°u Ã½:** Training model cÃ³ thá»ƒ máº¥t 30-60 phÃºt tÃ¹y vÃ o cáº¥u hÃ¬nh.

---

## BÆ¯á»šC 5: Push Model lÃªn HDFS

### 5.1. Náº¿u model Ä‘Ã£ cÃ³ á»Ÿ local (`/app/src/batch/als_model_32m`):

```bash
# Váº«n trong container app
python3 /app/scripts/push_model_to_hdfs.py
```

### 5.2. Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c push:

```bash
hdfs dfs -ls /user/hadoop/als_model
```

**Káº¿t quáº£ mong Ä‘á»£i:** Tháº¥y cÃ¡c file metadata vÃ  factors.

---

## BÆ¯á»šC 6: Cháº¡y Batch Job (Write Recommendations)

### 6.1. Cháº¡y script write recommendations:

```bash
# Váº«n trong container app
spark-submit \
  --packages com.datastax.spark:spark-cassandra-connector_2.12:3.4.1 \
  /app/src/batch/write_recommendations.py
```

### 6.2. Kiá»ƒm tra káº¿t quáº£:

```bash
# Kiá»ƒm tra Cassandra cÃ³ data chÆ°a
python3 -c "from utils import cassandra_connector as cc; cc.create_keyspace_and_table(); print(cc.read_recs('1'))"
```

**Káº¿t quáº£ mong Ä‘á»£i:** In ra list movie IDs (vÃ­ dá»¥: `['13399', '27373', ...]`)

---

## BÆ¯á»šC 7: Táº¡o Kafka Topic

### 7.1. Táº¡o topic `new_ratings`:

**CÃ¡ch 1: DÃ¹ng kafka-topics (KhuyÃªn dÃ¹ng):**

```bash
# Tá»« Ubuntu (khÃ´ng cáº§n vÃ o container)
docker compose exec kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic new_ratings \
  --partitions 1 \
  --replication-factor 1

# Hoáº·c tá»« trong container kafka
docker compose exec kafka bash
kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic new_ratings \
  --partitions 1 \
  --replication-factor 1
exit
```

**CÃ¡ch 2: DÃ¹ng Python (tá»« container app):**

```bash
# VÃ o container app
docker compose exec app bash

# CÃ i kafka-python náº¿u chÆ°a cÃ³
pip install kafka-python

# Táº¡o topic báº±ng Python
python3 << 'EOF'
from kafka.admin import KafkaAdminClient, NewTopic
from kafka.errors import TopicAlreadyExistsError

admin_client = KafkaAdminClient(
    bootstrap_servers=['kafka:9092'],
    client_id='admin'
)

topic = NewTopic(name='new_ratings', num_partitions=1, replication_factor=1)

try:
    admin_client.create_topics(new_topics=[topic], validate_only=False)
    print("âœ… Topic 'new_ratings' Ä‘Ã£ Ä‘Æ°á»£c táº¡o")
except TopicAlreadyExistsError:
    print("â„¹ï¸ Topic 'new_ratings' Ä‘Ã£ tá»“n táº¡i")
EOF
```

### 7.2. Kiá»ƒm tra topic Ä‘Ã£ táº¡o:

```bash
# Tá»« Ubuntu
docker compose exec kafka kafka-topics --list --bootstrap-server localhost:9092

# Xem chi tiáº¿t topic
docker compose exec kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic new_ratings
```

---

## BÆ¯á»šC 8: Cháº¡y Stream Processing

### 8.1. Má»Ÿ terminal Má»šI trÃªn Ubuntu:

```bash
# Má»Ÿ terminal má»›i (Ctrl+Shift+T hoáº·c táº¡o tab má»›i)
# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd /mnt/d/Big_Data/Movie_Recommendation_System

# VÃ o container app
docker compose exec app bash
```

### 8.2. Kiá»ƒm tra file script cÃ³ tá»“n táº¡i:

```bash
# Kiá»ƒm tra file
ls -la /app/src/stream/process_stream.py

# Xem ná»™i dung (Ä‘á»ƒ Ä‘áº£m báº£o Ä‘Ãºng file)
head -20 /app/src/stream/process_stream.py
```

### 8.3. Cháº¡y Spark Streaming:

```bash
# Cháº¡y vá»›i packages cáº§n thiáº¿t
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,com.datastax.spark:spark-cassandra-connector_2.12:3.4.1 \
  /app/src/stream/process_stream.py

# Hoáº·c náº¿u packages Ä‘Ã£ Ä‘Æ°á»£c cache, cÃ³ thá»ƒ bá» qua
# spark-submit /app/src/stream/process_stream.py
```

### 8.3. Kiá»ƒm tra logs:

**Káº¿t quáº£ mong Ä‘á»£i:**
```
âœ… ÄÃ£ import Cassandra_connector thÃ nh cÃ´ng!
Khá»Ÿi Ä‘á»™ng job Spark Streaming (Lá»šP SPEED - PHIÃŠN Báº¢N THáº¬T)...
ÄÃ£ káº¿t ná»‘i Kafka, Ä‘ang láº¯ng nghe topic 'new_ratings'...
ÄÃ£ khá»Ÿi Ä‘á»™ng query, Ä‘ang chá» data...
```

**Giá»¯ terminal nÃ y cháº¡y!** (Stream processing cháº¡y liÃªn tá»¥c)

---

## BÆ¯á»šC 9: Cháº¡y Web Application

### 9.1. Má»Ÿ terminal Má»šI trÃªn Ubuntu (thá»© 3):

```bash
# Má»Ÿ terminal má»›i (Ctrl+Shift+T hoáº·c táº¡o tab má»›i)
# Di chuyá»ƒn vÃ o thÆ° má»¥c project
cd /mnt/d/Big_Data/Movie_Recommendation_System

# VÃ o container app
docker compose exec app bash
```

### 9.2. Kiá»ƒm tra vÃ  cháº¡y Flask app:

```bash
# Kiá»ƒm tra file app.py
ls -la /app/src/webapp/app.py

# Kiá»ƒm tra dependencies
python3 -c "import flask; print('Flask OK')"
python3 -c "import pandas; print('Pandas OK')"

# Di chuyá»ƒn vÃ o thÆ° má»¥c app
cd /app

# Cháº¡y Flask app
python3 src/webapp/app.py

# Hoáº·c cháº¡y vá»›i debug mode (náº¿u cáº§n)
# FLASK_DEBUG=1 python3 src/webapp/app.py
```

### 9.3. Kiá»ƒm tra webapp:

Má»Ÿ browser: **http://localhost:5000**

**Káº¿t quáº£ mong Ä‘á»£i:** Tháº¥y giao diá»‡n web vá»›i form nháº­p User ID.

---

## BÆ¯á»šC 10: Test Há»‡ Thá»‘ng

### 10.1. Test Ä‘á»c recommendations:

1. Má»Ÿ browser: http://localhost:5000
2. Nháº­p User ID: `1`
3. Click "Xem Gá»£i Ã"
4. **Káº¿t quáº£:** Tháº¥y danh sÃ¡ch 10 phim Ä‘Æ°á»£c gá»£i Ã½

### 10.2. Test gá»­i rating má»›i:

1. Trong webapp, nháº­p:
   - User ID: `1`
   - Movie ID: `123` (hoáº·c báº¥t ká»³)
   - Rating: `4.5`
2. Click "Gá»­i Rating"
3. **Káº¿t quáº£:** Tháº¥y message "ÄÃ£ gá»­i rating vÃ o Kafka!"

### 10.3. Kiá»ƒm tra Stream Processing Ä‘Ã£ xá»­ lÃ½:

1. Xem terminal Spark Streaming (BÆ°á»›c 8)
2. **Káº¿t quáº£ mong Ä‘á»£i:** Tháº¥y log:
   ```
   Äang xá»­ lÃ½ Batch ID: X
   Batch X cÃ³ Y ratings má»›i.
   --- [REAL MODEL] Äang tÃ­nh toÃ¡n Top 10 cho Z user...
   --- [REAL DB] ÄÃ£ ghi xong Z users vÃ o Cassandra
   ```

### 10.4. Test cáº­p nháº­t recommendations:

1. Äá»£i ~15 giÃ¢y (trigger time)
2. Refresh webapp
3. Nháº­p láº¡i User ID: `1`
4. Click "Xem Gá»£i Ã"
5. **Káº¿t quáº£:** Tháº¥y top 10 má»›i (cÃ³ thá»ƒ khÃ¡c vá»›i láº§n trÆ°á»›c)

---

## ğŸ”§ TROUBLESHOOTING

### Lá»—i: "Failed to find data source: kafka"

**Giáº£i phÃ¡p:** ThÃªm `--packages` vÃ o spark-submit:
```bash
spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 \
  /app/src/stream/process_stream.py
```

### Lá»—i: "UnknownTopicOrPartitionException"

**Giáº£i phÃ¡p:** Táº¡o topic trÆ°á»›c (BÆ°á»›c 7)

### Lá»—i: "Cannot connect to Cassandra"

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra Cassandra Ä‘ang cháº¡y
docker compose ps cassandra

# Äá»£i Cassandra khá»Ÿi Ä‘á»™ng (30-60 giÃ¢y)
docker compose logs cassandra
```

### Lá»—i: "Model not found"

**Giáº£i phÃ¡p:** 
1. Kiá»ƒm tra model Ä‘Ã£ Ä‘Æ°á»£c push lÃªn HDFS (BÆ°á»›c 5)
2. Hoáº·c train model má»›i (BÆ°á»›c 4)

---

## ğŸ“ TÃ“M Táº®T CÃC TERMINAL

Khi há»‡ thá»‘ng cháº¡y Ä‘áº§y Ä‘á»§, báº¡n cáº§n **3 terminals**:

1. **Terminal 1:** Spark Streaming (BÆ°á»›c 8)
   ```bash
   spark-submit ... process_stream.py
   ```

2. **Terminal 2:** Web Application (BÆ°á»›c 9)
   ```bash
   python3 src/webapp/app.py
   ```

3. **Terminal 3:** DÃ¹ng Ä‘á»ƒ test/check logs
   ```bash
   docker compose logs -f
   ```

---

## ğŸ¯ CHECKLIST HOÃ€N THÃ€NH

- [ ] Docker containers Ä‘ang cháº¡y
- [ ] HDFS Ä‘Ã£ setup vÃ  cÃ³ data
- [ ] Model Ä‘Ã£ Ä‘Æ°á»£c train vÃ  push lÃªn HDFS
- [ ] Batch job Ä‘Ã£ cháº¡y (Cassandra cÃ³ recommendations)
- [ ] Kafka topic `new_ratings` Ä‘Ã£ táº¡o
- [ ] Spark Streaming Ä‘ang cháº¡y
- [ ] Web Application Ä‘ang cháº¡y
- [ ] Test Ä‘á»c recommendations thÃ nh cÃ´ng
- [ ] Test gá»­i rating thÃ nh cÃ´ng
- [ ] Test cáº­p nháº­t recommendations thÃ nh cÃ´ng

---

## ğŸš€ Láº¦N SAU KHI Má» Láº I

Náº¿u Ä‘Ã£ setup xong, chá»‰ cáº§n:

1. **Khá»Ÿi Ä‘á»™ng Docker:**
   ```bash
   docker compose up -d
   ```

2. **Cháº¡y Spark Streaming** (Terminal 1):
   ```bash
   docker compose exec app bash
   spark-submit --packages ... /app/src/stream/process_stream.py
   ```

3. **Cháº¡y Web Application** (Terminal 2):
   ```bash
   docker compose exec app bash
   python3 src/webapp/app.py
   ```

4. **Má»Ÿ browser:** http://localhost:5000

---

**ChÃºc báº¡n thÃ nh cÃ´ng! ğŸ‰**