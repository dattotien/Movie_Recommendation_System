# Movie_Recommendation_System

## Table of Contents
- [1. Project Overview](#1-project-overview)
- [2. Use Case & Industry Background](#2-use-case--industry-background)
- [3. Dataset Overview](#3-dataset-overview)
- [4. System Architecture](#4-system-architecture)
- [5. Workflow Explanation](#5-workflow-explanation)
  - [Batch Processing](#batch-processing)
  - [Speed Processing](#speed-processing)
- [6. Repository Structure](#6-repository-structure)
- [7. Installation & Requirements](#7-installation--requirements)
- [8. How to Run the Project](#8-how-to-run-the-project)
- [9. Team Responsibilities](#9-team-responsibilities)
- [10. Acknowledgments](#10-acknowledgments)

---

# 1. Project Overview
![Model](Move-recommendation-system.jpg)
This project is a **Movie Recommendation System** built entirely using **Big Data technologies**, designed under the **Lambda Architecture**.  
It combines:

- **Batch Layer** â†’ Train ALS model on 32M MovieLens ratings (Spark MLlib)
- **Speed Layer** â†’ Real-time recommendation updates via Kafka + Spark Streaming
- **Serving Layer** â†’ Cassandra as low-latency data store
- **Web Demo** â†’ Flask/Streamlit app for querying recommendations

The system outputs **Top-10 personalized movie recommendations** for every user, updated instantly when new ratings arrive.

---

# 2. Use Case & Industry Background
### **Use Case: Product/Content Recommendation Engine**
Recommendation systems are used by:
- Netflix  
- YouTube  
- Shopee  
- Spotify  
- TikTok  

### **Industries**
- E-commerce  
- Media Streaming  
- Social Networks  

### Big Data Frameworks Used
| Framework | Purpose |
|----------|----------|
| **Apache Spark** | Batch ETL + ALS model training |
| **Apache Kafka** | Ingest new user ratings in real-time |
| **Apache Flink** | (Optional extension) Real-time processing |
| **Hadoop MapReduce** | Large-scale offline preprocessing |
| **HDFS** | Distributed storage |
| **Cassandra** | Low-latency storage for recommendations |

---

# 3. Dataset Overview
ğŸ“Œ **Dataset: MovieLens 32M**  
ğŸ“Œ **Link:** https://www.kaggle.com/datasets/dattotien/bigdata-movies  

### Content
| File | Description |
|------|-------------|
| `ratings.csv` | 32M ratings (userId, movieId, rating, timestamp) |
| `movies.csv` | Movie details (movieId, title, genres) |
| `tags.csv` | 2M user-generated tags |
| `links.csv` | Mapping to IMDb, TMDB, MovieLens |

The dataset includes:
- â­ **32,000,000 ratings**
- ğŸ¬ **87,585 movies**
- ğŸ‘¤ **200,000+ users**
- ğŸ·ï¸ **2,000,000 tags**

Two versions included:
- `ml-1m` â†’ For testing & debugging  
- `ml-32m` â†’ Full-scale final processing  

---

# 4. System Architecture

The project implements the **Lambda Architecture** with 3 primary, complementary layers:

- **Batch Layer (HDFS, Spark MLlib):** Computes high-accuracy "Batch Views" (full historical model retraining).
- **Speed Layer (Kafka, Spark Streaming):** Processes new data streams to generate instant "Real-time Views".
- **Serving Layer (Cassandra):** Merges results from both layers, ensuring extremely low query latency.

---

# 5. Workflow Explanation

## <a name="batch-processing"></a>Batch Processing (Historical Layer)

1. **Ingestion:** Historical and accumulated data is stored in **HDFS**.
2. **Training:** **Spark MLlib** periodically retrains the **ALS** model on the entire dataset.
3. **Output:** Pre-calculated recommendations are written to **Cassandra** as the **Batch View**.

---

## <a name="speed-processing"></a>Speed Processing (Real-time Layer)

1. **Event Ingestion:** New user rating events are ingested through **Apache Kafka**.
2. **Inference:** **Spark Streaming** loads the ALS model and updates recommendations **only for users with new interactions**.
3. **Update:** Real-time recommendations are written instantly to **Cassandra** as the **Speed View**.

---

# 6. Repository Structure
```
Movie_Recommendation_System/
â”‚
â”œâ”€â”€ ğŸ“„ README.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Main documentation
â”œâ”€â”€ ğŸ“„ QUICK_START.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Quick start guide
â”œâ”€â”€ ğŸ“„ SETUP_GUIDE.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Detailed setup guide
â”œâ”€â”€ ğŸ“„ requirements.txtÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â # List of Python libraries
â”œâ”€â”€ ğŸ“„ docker-compose.ymlÂ  Â  Â  Â  Â  Â  Â  Â  Â # Docker Compose configuration
â”œâ”€â”€ ğŸ“„ DockerfileÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Docker image configuration
â”œâ”€â”€ ğŸ“„ core-site.xmlÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # HDFS configuration
â”‚
â”œâ”€â”€ ğŸ“ src/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Main source code
â”‚Â  Â â”œâ”€â”€ ğŸ“ batch/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Batch processing (Spark)
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ train_model.ipynbÂ  Â  Â  Â  Â  Â  Â # Model training notebook
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ write_recommendations.pyÂ  Â  Â  # Writes recommendations to Cassandra
â”‚Â  Â â”‚Â  Â â””â”€â”€ ğŸ“ als_model_32m/Â  Â  Â  Â  Â  Â  Â # Trained ALS model
â”‚Â  Â â”‚Â  Â  Â  Â â”œâ”€â”€ ğŸ“ itemFactors/Â  Â  Â  Â  Â  Â # Movie factor matrix (100+ .parquet files)
â”‚Â  Â â”‚Â  Â  Â  Â â”œâ”€â”€ ğŸ“ userFactors/Â  Â  Â  Â  Â  Â # User factor matrix (100+ .parquet files)
â”‚Â  Â â”‚Â  Â  Â  Â â””â”€â”€ ğŸ“ metadata/Â  Â  Â  Â  Â  Â  Â  # Model metadata
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ ğŸ“ online/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Online recommendations processing
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ user_factor_utils.pyÂ  Â  Â  Â  Â  # Online computation utilities
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ ğŸ“ stream/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Streaming processing (Spark Streaming)
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ process_stream.pyÂ  Â  Â  Â  Â  Â  Â # Processes real-time ratings from Kafka
â”‚Â  Â â”‚
â”‚Â  Â â”œâ”€â”€ ğŸ“ utils/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # General utilities
â”‚Â  Â â”‚Â  Â â”œâ”€â”€ __init__.py
â”‚Â  Â â”‚Â  Â â””â”€â”€ cassandra_connector.pyÂ  Â  Â  Â  # Cassandra connector
â”‚Â  Â â”‚
â”‚Â  Â â””â”€â”€ ğŸ“ webapp/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Flask web application
â”‚Â  Â  Â  Â â”œâ”€â”€ app.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Main Flask application
â”‚Â  Â  Â  Â â”œâ”€â”€ README.mdÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Webapp documentation
â”‚Â  Â  Â  Â â”œâ”€â”€ ğŸ“ static/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Static resources (CSS, JS, images)
â”‚Â  Â  Â  Â â””â”€â”€ ğŸ“ templates/Â  Â  Â  Â  Â  Â  Â  Â  Â # HTML templates
â”‚Â  Â  Â  Â  Â  Â â”œâ”€â”€ index.htmlÂ  Â  Â  Â  Â  Â  Â  Â  # Home page
â”‚Â  Â  Â  Â  Â  Â â””â”€â”€ movie_details.htmlÂ  Â  Â  Â  # Movie details page
â”‚
â”œâ”€â”€ ğŸ“ scripts/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Utility scripts
â”‚Â  Â â”œâ”€â”€ setup_env.shÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Environment setup
â”‚Â  Â â”œâ”€â”€ load_to_hdfs.shÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â # Load data to HDFS
â”‚Â  Â â”œâ”€â”€ push_model_to_hdfs.pyÂ  Â  Â  Â  Â  Â  Â # Push model to HDFS
â”‚Â  Â â”œâ”€â”€ check_and_push_model.shÂ  Â  Â  Â  Â  Â # Check and push model
â”‚Â  Â â”œâ”€â”€ kafka_producer.pyÂ  Â  Â  Â  Â  Â  Â  Â  Â # Producer sends data to Kafka
â”‚
â”‚
â”œâ”€â”€ ğŸ“ notebooks/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Jupyter Notebooks
â”‚Â  Â â””â”€â”€ 01-EDA-MovieLens.ipynbÂ  Â  Â  Â  Â  Â # MovieLens data analysis
â”‚
â”œâ”€â”€ ğŸ“ data/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Input data
â”‚Â  Â â”œâ”€â”€ ğŸ“ ml-1m/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # MovieLens 1M Dataset
â”‚Â  Â â”‚Â  Â â””â”€â”€ ğŸ“ ml-1m/
â”‚Â  Â â””â”€â”€ ğŸ“ ml-32m/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # MovieLens 32M Dataset
â”‚Â  Â  Â  Â â””â”€â”€ ğŸ“ ml-32m/
â”‚
â””â”€â”€ ğŸ“ cassandra_data_storage/Â  Â  Â  Â  Â  Â  # Cassandra data (persistent)
Â  Â  â”œâ”€â”€ ğŸ“ commitlog/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â # Commit logs
Â  Â  â”œâ”€â”€ ğŸ“ data/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Cassandra data
Â  Â  â”‚Â  Â â”œâ”€â”€ ğŸ“ movie_recs/Â  Â  Â  Â  Â  Â  Â  Â  # Recommendations keyspace
Â  Â  â”‚Â  Â â”‚Â  Â â””â”€â”€ ğŸ“ user_recommendations-*/ # user_recommendations table
Â  Â  â”‚Â  Â â”œâ”€â”€ ğŸ“ system/Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Cassandra system
Â  Â  â”‚Â  Â â”œâ”€â”€ ğŸ“ system_auth/Â  Â  Â  Â  Â  Â  Â  Â # Authentication
Â  Â  â”‚Â  Â â”œâ”€â”€ ğŸ“ system_distributed/Â  Â  Â  Â  # Distributed system
Â  Â  â”‚Â  Â â”œâ”€â”€ ğŸ“ system_schema/Â  Â  Â  Â  Â  Â  Â # Schema metadata
Â  Â  â”‚Â  Â â””â”€â”€ ğŸ“ system_traces/Â  Â  Â  Â  Â  Â  Â # Traces
Â  Â  â””â”€â”€ ğŸ“ saved_caches/Â  Â  Â  Â  Â  Â  Â  Â  Â  # Saved caches
```       


---

# 7. Installation & Requirements
The entire ecosystem is **Dockerized** using `docker-compose.yml`.

**Prerequisites:**
1.  Docker Engine
2.  Docker Compose
3.  Resource Recommendation: Minimum 16GB RAM (required for Spark's In-memory processing).

---

# 8. How to Run the Project
Follow these steps to set up and start the complete Movie Recommendation System, which includes batch processing, real-time streaming, and the Flask web application.
1.  **Clone the repository.** 
`git clone <REPOSITORY_URL>`, 
`cd Movie_Recommendation_System`
2.  **Start the Cluster:** Execute `docker-compose up -d`.
3.  **Ingest Data:** Run the ingestion script: `./scripts/load_to_hdfs.sh`.
4.  **Run Batch Job:** Execute the Spark Batch training process. `docker compose exec app bash`
  - Run the Spark Batch job to write initial recommendations `spark-submit /app/src/batch/write_recommendations.py`
5. **Run Web App:** Launch the Flask application to query recommendations.
    - Enter the application container `docker compose exec app bash` `python3 src/webapp/app.py`
    - After testing the web application and creating a user rating, that rating will be emitted to the stream (Kafka).
6.  **Run Streaming Job:** Start the Spark Streaming process.
  - Enter the application container `docker compose exec app bash`
  - Navigate to the app directory inside the container `cd /app`
  - Run the Spark Streaming job with required packages `spark-submit \--packages \org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1,\com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.3.0 \src/stream/process_stream.py`
  - âš ï¸ KEEP THIS TERMINAL RUNNING! Do NOT close it while the system is in use.
---
The system is fully operational. Access the web interface at: http://127.0.0.1:5000/
# 9. Team Responsibilities

| Name | Responsibilities |
|:---:|:---|
| **TÃ´ Tiáº¿n Äáº¡t** | Cassandra Schema Design, Spark-to-Cassandra connection module, Flask Web Application development |
| **Pháº¡m HÃ  Anh** | Data Analysis (EDA) on MovieLens, Data Ingestion script (ETL to HDFS), **Spark Batch** module development (ALS training) |
| **Chu Thá»‹ PhÆ°Æ¡ng Anh** | Apache Kafka cluster configuration, **Producer** script for real-time rating stream, **Spark Streaming** module development. |

---

# 10. Acknowledgments
We acknowledge the pioneering work of **Nathan Marz** (Lambda Architecture) and **GroupLens Research** (MovieLens Dataset). Special thanks to Dr. Tráº§n Há»“ng Viá»‡t for guidance.

---
